{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076783c1-8482-4bbc-95c2-8dbce0c4812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\pcm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\pcm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2113eef-1cc0-4a89-8d95-919d0e52c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BigDataAnalysis\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b29eb99c-d955-4c1b-a4ff-8547b278978c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+------+----------+\n",
      "|EmployeeID|  Name|Department|Salary|Experience|\n",
      "+----------+------+----------+------+----------+\n",
      "|         1| Grace|   Finance| 89401|        22|\n",
      "|         2| David|   Finance| 84602|        29|\n",
      "|         3|Hannah|        HR| 32814|        17|\n",
      "|         4|  Emma| Marketing| 81207|        21|\n",
      "|         5| Grace| Marketing| 32308|        13|\n",
      "+----------+------+----------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load Large Datasets\n",
    "df = spark.read.csv(r\"C:\\Users\\pcm\\OneDrive\\Desktop\\CODTECH Internship\\bigdata_employees.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "799c446a-057f-4fea-a79e-bb30087772a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EmployeeID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Data Exploration\n",
    "#Check the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9f1835-ab94-4c01-abc3-e68f4a98b24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------+----------+-----------------+-----------------+\n",
      "|summary|       EmployeeID|  Name|Department|           Salary|       Experience|\n",
      "+-------+-----------------+------+----------+-----------------+-----------------+\n",
      "|  count|           100000|100000|    100000|           100000|           100000|\n",
      "|   mean|          50000.5|  NULL|      NULL|      75126.43523|         14.98501|\n",
      "| stddev|28867.65779668774|  NULL|      NULL|25913.91447592236|8.379301129973472|\n",
      "|    min|                1| Alice|   Finance|            30000|                1|\n",
      "|    max|           100000|  Jack|     Sales|           119999|               29|\n",
      "+-------+-----------------+------+----------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check data statistics\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a7dc96-a256-4900-bca3-a0210bb3fed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count records\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcdb422a-8018-4611-a9d0-ff85bf0ac831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "#Handle missing values\n",
    "df = df.dropna()  # Drop rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07022f05-12c9-40de-98fd-da57677d0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates\n",
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d90d196c-53ee-42c6-ba4e-1900999b57f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data\n",
    "df_filtered = df.filter(df[\"salary\"] > 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1167ccab-9cdd-452b-910c-9be6a4b91bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Transformation\n",
    "#Convert column types\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn(\"salary\", col(\"salary\").cast(\"double\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ae6eb15-9a86-4521-9da3-a6a1fadbfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new columns\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = df.withColumn(\"salary_category\", when(df.salary > 60000, \"High\").otherwise(\"Low\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cb6423e-8785-4ee9-a0cd-49adedc546d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|department|count|\n",
      "+----------+-----+\n",
      "|     Sales|20066|\n",
      "|        HR|19852|\n",
      "|   Finance|19873|\n",
      "| Marketing|19991|\n",
      "|        IT|20218|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aggregations\n",
    "#Group by and count:\n",
    "df.groupBy(\"department\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a25d60fd-b937-49da-a0fc-25efb40b30ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|department|      avg(salary)|\n",
      "+----------+-----------------+\n",
      "|     Sales|75352.31067477325|\n",
      "|        HR|74966.79105379811|\n",
      "|   Finance|75102.55220651135|\n",
      "| Marketing|75269.87639437747|\n",
      "|        IT|74940.65693936097|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find the average salary per department\n",
    "df.groupBy(\"department\").avg(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c34aa72-199d-4665-815e-d15f7d6c0928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|department|      avg(salary)|\n",
      "+----------+-----------------+\n",
      "|     Sales|75352.31067477325|\n",
      "|        HR|74966.79105379811|\n",
      "|   Finance|75102.55220651135|\n",
      "| Marketing|75269.87639437747|\n",
      "|        IT|74940.65693936097|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL Queries\n",
    "#Convert PySpark DataFrame to a SQL table\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "spark.sql(\"SELECT department, AVG(salary) FROM employees GROUP BY department\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a96a6c4-63f7-4e05-90c2-6e188d47e8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+--------+----------+---------------+\n",
      "|EmployeeID|   Name|Department|  salary|Experience|salary_category|\n",
      "+----------+-------+----------+--------+----------+---------------+\n",
      "|        13| Hannah|     Sales| 79460.0|        28|           High|\n",
      "|       152|  Grace|        IT|110739.0|        14|           High|\n",
      "|       259|  Isaac|        IT|113141.0|         7|           High|\n",
      "|       500|Charlie|        IT| 92402.0|        29|           High|\n",
      "|       512|  Isaac| Marketing| 95750.0|        19|           High|\n",
      "|       549|   Emma|        HR|110472.0|         6|           High|\n",
      "|       599|  Alice|        IT|115290.0|         3|           High|\n",
      "|       689|Charlie| Marketing| 46918.0|        16|            Low|\n",
      "|      1363| Hannah|   Finance| 91911.0|         7|           High|\n",
      "|      1734|  David|     Sales| 66205.0|         8|           High|\n",
      "|      2244|  Alice|        HR| 39136.0|         1|            Low|\n",
      "|      2611|   Jack|   Finance|119725.0|        14|           High|\n",
      "|      3055| Hannah|   Finance| 81854.0|         7|           High|\n",
      "|      3084|   Emma|   Finance|117831.0|        28|           High|\n",
      "|      3229|    Bob|        HR|119650.0|        12|           High|\n",
      "|      3939|  David|   Finance| 71826.0|        24|           High|\n",
      "|      4061|Charlie|        HR| 31100.0|         2|            Low|\n",
      "|      4130|   Emma|        IT| 79150.0|         1|           High|\n",
      "|      4263| Hannah|        IT| 61108.0|         4|           High|\n",
      "|      4535|  Isaac|   Finance|108462.0|         1|           High|\n",
      "+----------+-------+----------+--------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use cache() or persist() for frequent queries\n",
    "df.cache()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f307d2e2-6174-4e5b-82ef-e84a5758e22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+------------------+\n",
      "|       features|  salary|        prediction|\n",
      "+---------------+--------+------------------+\n",
      "| [28.0,79460.0]| 79460.0| 79459.99999999999|\n",
      "|[14.0,110739.0]|110739.0|110738.99999999997|\n",
      "| [7.0,113141.0]|113141.0|113140.99999999997|\n",
      "| [29.0,92402.0]| 92402.0| 92401.99999999997|\n",
      "| [19.0,95750.0]| 95750.0| 95749.99999999997|\n",
      "| [6.0,110472.0]|110472.0|110471.99999999997|\n",
      "| [3.0,115290.0]|115290.0|115289.99999999997|\n",
      "| [16.0,46918.0]| 46918.0| 46918.00000000001|\n",
      "|  [7.0,91911.0]| 91911.0| 91910.99999999997|\n",
      "|  [8.0,66205.0]| 66205.0| 66204.99999999999|\n",
      "|  [1.0,39136.0]| 39136.0|39136.000000000015|\n",
      "|[14.0,119725.0]|119725.0|119724.99999999996|\n",
      "|  [7.0,81854.0]| 81854.0| 81853.99999999999|\n",
      "|[28.0,117831.0]|117831.0|117830.99999999997|\n",
      "|[12.0,119650.0]|119650.0|119649.99999999996|\n",
      "| [24.0,71826.0]| 71826.0| 71825.99999999999|\n",
      "|  [2.0,31100.0]| 31100.0| 31100.00000000002|\n",
      "|  [1.0,79150.0]| 79150.0| 79149.99999999999|\n",
      "|  [4.0,61108.0]| 61108.0|           61108.0|\n",
      "| [1.0,108462.0]|108462.0|108461.99999999997|\n",
      "+---------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Machine Learning with PySpark\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Prepare features\n",
    "assembler = VectorAssembler(inputCols=[\"Experience\", \"salary\"], outputCol=\"features\")\n",
    "df_ml = assembler.transform(df)\n",
    "\n",
    "# Train a model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"salary\")\n",
    "model = lr.fit(df_ml)\n",
    "\n",
    "# Predict\n",
    "predictions = model.transform(df_ml)\n",
    "predictions.select(\"features\", \"salary\", \"prediction\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
